{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_image import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using T2I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_diffusion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \"extra digit, fewer digits, cropped, worst quality, low quality, glitch, deformed, mutated, ugly, disfigured\"\n",
    "\n",
    "# replace prompt as required by reference image\n",
    "\n",
    "prompt=[\"Beautiful, carpet, 4k picture, high quality, color gradient rainbow , make it dim , similar to input image\",\n",
    "       \"pattern,orange,red,yellow,purple,blue,artistic,floral,lace,motifs\",\n",
    "        \"design,abstract,rich,dynamic,swirls,deep,vivid,decorative,warm,complex\",\n",
    "        \"intricate,colorful,ornate,paisley,floral,detailed,swirling,vibrant,textured,elegant\",\n",
    "        \"motifs,artistic,pattern,deep,warm,vivid,intricate,ornate,colorful,dynamic\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=5 # keep steps same as number of prompts and the image you want to generate\n",
    "for i in range(steps):\n",
    "  gen_images = pipe(\n",
    "    prompt=prompt[i],\n",
    "    negative_prompt=negative_prompt,\n",
    "    image=image,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7,\n",
    "    adapter_conditioning_scale=0.9,\n",
    "    adapter_conditioning_factor=1\n",
    "  ).images[0]\n",
    "  gen_images.save(f'images/out_carpet{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference using IP adapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "\n",
    "pipeline = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipeline.load_ip_adapter(\"h94/IP-Adapter\", subfolder=\"sdxl_models\", weight_name=\"ip-adapter_sdxl.bin\")\n",
    "pipeline.set_ip_adapter_scale(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(\"https://designcompetition.explorug.online/images/Border/2/16.webp\")\n",
    "ip_image = load_image(\"https://designcompetition.explorug.online/images/Border/2/17.webp\")\n",
    "\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(4)\n",
    "images_l=[]\n",
    "for _ in range(5):\n",
    "    images = pipeline(\n",
    "        prompt=\"best quality, high quality\",\n",
    "        image=image,\n",
    "        ip_adapter_image=ip_image,\n",
    "        generator=generator,\n",
    "        strength=0.6,\n",
    "    ).images[0]\n",
    "    images_l.append(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_l[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer using stable_diffusion with clip\n",
    "CLIP interogator generates prompts for the input/reference image , that prompt is passed through runway/stable_diffusion to generate new images that resembles original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export REPLICATE_API_TOKEN=<your_api_token> # from https://replicate.com/pharmapsychotic/clip-interrogator/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"image\": \"path_to_your_image\",  # Corrected file extension\n",
    "    \"clip_model_name\": \"ViT-L/14\"\n",
    "}\n",
    "\n",
    "# Run the model\n",
    "try:\n",
    "    output = replicate.run(\n",
    "        \"pharmapsychotic/clip-interrogator:8151e1c9f47e696fa316146a2e35812ccf79cfc9eba05b11c7f450155102af70\",\n",
    "        input=input\n",
    "    )\n",
    "    print(output)\n",
    "except replicate.exceptions.ReplicateError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call stability api\n",
    "from io import BytesIO\n",
    "import IPython\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Connect to the Stability API\n",
    "\n",
    "import getpass\n",
    "# @markdown To get your API key visit https://platform.stability.ai/account/keys\n",
    "STABILITY_KEY = getpass.getpass('<your_api_key>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define functions\n",
    "\n",
    "def send_generation_request(\n",
    "    host,\n",
    "    params,\n",
    "):\n",
    "    headers = {\n",
    "        \"Accept\": \"image/*\",\n",
    "        \"Authorization\": f\"Bearer {STABILITY_KEY}\"\n",
    "    }\n",
    "\n",
    "    # Encode parameters\n",
    "    files = {}\n",
    "    image = params.pop(\"image\", None)\n",
    "    mask = params.pop(\"mask\", None)\n",
    "    if image is not None and image != '':\n",
    "        files[\"image\"] = open(image, 'rb')\n",
    "    if mask is not None and mask != '':\n",
    "        files[\"mask\"] = open(mask, 'rb')\n",
    "    if len(files)==0:\n",
    "        files[\"none\"] = ''\n",
    "\n",
    "    # Send request\n",
    "    print(f\"Sending REST request to {host}...\")\n",
    "    response = requests.post(\n",
    "        host,\n",
    "        headers=headers,\n",
    "        files=files,\n",
    "        data=params\n",
    "    )\n",
    "    if not response.ok:\n",
    "        raise Exception(f\"HTTP {response.status_code}: {response.text}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image =\" path_to_image\" #@param {type:\"string\"}\n",
    "prompt = output\n",
    "negative_prompt = \"cropped, worst quality, low quality, glitch, deformed, mutated, ugly, disfigured\" #@param {type:\"string\"}\n",
    "seed = 1337 #@param {type:\"integer\"}\n",
    "output_format = \"jpeg\" #@param [\"jpeg\", \"png\"]\n",
    "strength = 0.75 #@param {type:\"slider\", min:0.0, max: 1.0, step: 0.01}\n",
    "\n",
    "host = f\"https://api.stability.ai/v2beta/stable-image/generate/sd3\"\n",
    "\n",
    "params = {\n",
    "    \"image\" : image,\n",
    "    \"prompt\" : prompt,\n",
    "    \"negative_prompt\" : negative_prompt,\n",
    "    \"strength\" : strength,\n",
    "    \"seed\" : seed,\n",
    "    \"output_format\": output_format,\n",
    "    \"model\" : \"sd3.5-large\",\n",
    "    \"mode\" : \"image-to-image\"\n",
    "}\n",
    "\n",
    "response = send_generation_request(\n",
    "    host,\n",
    "    params\n",
    ")\n",
    "\n",
    "# Decode response\n",
    "output_image = response.content\n",
    "finish_reason = response.headers.get(\"finish-reason\")\n",
    "seed = response.headers.get(\"seed\")\n",
    "\n",
    "# Check for NSFW classification\n",
    "if finish_reason == 'CONTENT_FILTERED':\n",
    "    raise Warning(\"Generation failed NSFW classifier\")\n",
    "\n",
    "# Save and display result\n",
    "generated = f\"images/generated_{seed}.{output_format}\"\n",
    "with open(generated, \"wb\") as f:\n",
    "    f.write(output_image)\n",
    "print(f\"Saved image {generated}\")\n",
    "\n",
    "output.no_vertical_scroll()\n",
    "print(\"Result image:\")\n",
    "IPython.display.display(Image.open(generated))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
