{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Total pattern groups: 6940\n",
      "\n",
      "Breakdown by root category:\n",
      "FHD 1163:\n",
      "  Patterns: 1164\n",
      "  Images: 5809\n",
      "GMIC PROD 477:\n",
      "  Patterns: 477\n",
      "  Images: 2385\n",
      "900x1200 4954:\n",
      "  Patterns: 5299\n",
      "  Images: 26492\n"
     ]
    }
   ],
   "source": [
    "class PatternDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.image_extensions = {'.png', '.jpg', '.jpeg'}\n",
    "        \n",
    "        # Keep track of processed directories to avoid duplicates\n",
    "        processed_dirs = set()\n",
    "        \n",
    "        for root, _, files in os.walk(root_dir):\n",
    "            # Get image files in current directory\n",
    "            image_files = [\n",
    "                os.path.join(root, f) for f in files\n",
    "                if os.path.splitext(f.lower())[1] in self.image_extensions\n",
    "            ]\n",
    "            \n",
    "            if image_files:\n",
    "                # Get full hierarchy information\n",
    "                rel_path = os.path.relpath(root, root_dir)\n",
    "                path_components = rel_path.split(os.sep)\n",
    "                \n",
    "                # Create structured metadata\n",
    "                pattern_info = {\n",
    "                    'root_category': path_components[0] if len(path_components) > 0 else '',\n",
    "                    'main_category': path_components[1] if len(path_components) > 1 else '',\n",
    "                    'sub_category': path_components[2] if len(path_components) > 2 else '',\n",
    "                    'pattern_id': path_components[-1],\n",
    "                    'full_path': root,\n",
    "                    'images': sorted(image_files)  # Sort to ensure consistent ordering\n",
    "                }\n",
    "                \n",
    "                # Only add if this directory hasn't been processed\n",
    "                if root not in processed_dirs:\n",
    "                    self.data.append(pattern_info)\n",
    "                    processed_dirs.add(root)\n",
    "        \n",
    "        # Sort data for consistent ordering\n",
    "        # self.data.sort(key=lambda x: x['full_path'])\n",
    "        \n",
    "        # Print dataset statistics\n",
    "        self._print_statistics()\n",
    "\n",
    "    def _print_statistics(self):\n",
    "        \"\"\"Print dataset statistics for verification\"\"\"\n",
    "        print(f\"\\nDataset Statistics:\")\n",
    "        print(f\"Total pattern groups: {len(self.data)}\")\n",
    "        \n",
    "        # Count by root category\n",
    "        root_cats = {}\n",
    "        for item in self.data:\n",
    "            root_cat = item['root_category']\n",
    "            if root_cat not in root_cats:\n",
    "                root_cats[root_cat] = {'patterns': 0, 'images': 0}\n",
    "            root_cats[root_cat]['patterns'] += 1\n",
    "            root_cats[root_cat]['images'] += len(item['images'])\n",
    "        \n",
    "        print(\"\\nBreakdown by root category:\")\n",
    "        for cat, stats in root_cats.items():\n",
    "            print(f\"{cat}:\")\n",
    "            print(f\"  Patterns: {stats['patterns']}\")\n",
    "            print(f\"  Images: {stats['images']}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            dict: Contains pattern information and images\n",
    "        \"\"\"\n",
    "        pattern_info = self.data[idx]\n",
    "        \n",
    "        # Load and transform images\n",
    "        images = []\n",
    "        for img_path in pattern_info['images']:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                images.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return {\n",
    "            'pattern_id': pattern_info['pattern_id'],\n",
    "            'root_category': pattern_info['root_category'],\n",
    "            'main_category': pattern_info['main_category'],\n",
    "            'sub_category': pattern_info['sub_category'],\n",
    "            'images': images,\n",
    "            'paths': pattern_info['images']\n",
    "        }\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),  \n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "root_dir = \"machine-learning-set/\"\n",
    "dataset = PatternDataset(root_dir=root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pattern 52600:\n",
      "Category: 900x1200 4954/JT3 708\n",
      "Images: 5\n",
      "Paths: ['0.png', '1.png', '2.png', '3.png', '4.png']\n",
      "\n",
      "Pattern 47129:\n",
      "Category: 900x1200 4954/JT3 708\n",
      "Images: 5\n",
      "Paths: ['0.png', '1.png', '2.png', '3.png', '4.png']\n",
      "\n",
      "Pattern 39508:\n",
      "Category: 900x1200 4954/JT3 708\n",
      "Images: 5\n",
      "Paths: ['0.png', '1.png', '2.png', '3.png', '4.png']\n",
      "\n",
      "Pattern 95952:\n",
      "Category: 900x1200 4954/JT3 708\n",
      "Images: 5\n",
      "Paths: ['0.png', '1.png', '2.png', '3.png', '4.png']\n",
      "\n",
      "Pattern 14634:\n",
      "Category: 900x1200 4954/JT3 708\n",
      "Images: 5\n",
      "Paths: ['0.png', '1.png', '2.png', '3.png', '4.png']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5500,5505):\n",
    "    sample = dataset[i]\n",
    "    print(f\"\\nPattern {sample['pattern_id']}:\")\n",
    "    print(f\"Category: {sample['root_category']}/{sample['main_category']}\")\n",
    "    print(f\"Images: {len(sample['images'])}\")\n",
    "    print(f\"Paths: {[os.path.basename(p) for p in sample['paths']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14634'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['pattern_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_image = sample['images'][1]\n",
    "print(f\"Tensor shape: {tensor_image.shape}\")\n",
    "\n",
    "tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))  # Adjust the figure size to fit all images\n",
    "\n",
    "# Iterate through each image and plot it\n",
    "for idx, tensor_image in enumerate(sample['images']):\n",
    "    plt.subplot(1, len(sample['images']), idx + 1)  # Create a subplot for each image\n",
    "    image = to_pil_image(sample['images'][idx])  # Convert tensor to PIL image (ulto para le parse garni C, H, W )\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis for cleaner display\n",
    "    plt.title(f\"Image {idx + 1}\")  # Optional: Add a title for each image\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6940"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    pattern_ids = [item[\"pattern_id\"] for item in batch]\n",
    "    root = [item[\"root_category\"] for item in batch]\n",
    "    images = [torch.stack(item[\"images\"]) for item in batch]  # Stack images for each pattern\n",
    "\n",
    "    return {\n",
    "        \"pattern_id\": pattern_ids,\n",
    "        \"root_category\":root,\n",
    "        \"images\": images  # Now a list of 4 tensors, each with shape (5, C, H, W)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,  # Number of patterns per batch\n",
    "    shuffle=True,  # Shuffle patterns for randomness\n",
    "    collate_fn=custom_collate,\n",
    "    num_workers=4  # Use multiple threads for data loading\n",
    ")\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in data_loader:\n",
    "    print(\"Batch:\")\n",
    "    print(f\"  Pattern IDs: {batch['pattern_id']}\")\n",
    "    print(f\"  Root Categories: {batch['root_category']}\")\n",
    "    # print(f\" Main categories:{batch['main_category']}\")\n",
    "    print(f\"  Number of Images per Pattern: {[len(imgs) for imgs in batch['images']]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of batch['images']: <class 'list'>\n",
      "Length of batch['images']: 4\n",
      "Type of first element: <class 'torch.Tensor'>\n",
      "Shape of first element: torch.Size([5, 3, 512, 512])\n",
      "Pattern 0: Shape = torch.Size([5, 3, 512, 512])\n",
      "Pattern 1: Shape = torch.Size([5, 3, 512, 512])\n",
      "Pattern 2: Shape = torch.Size([5, 3, 512, 512])\n",
      "Pattern 3: Shape = torch.Size([5, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Print general structure\n",
    "print(f\"Type of batch['images']: {type(batch['images'])}\")  # Should be list\n",
    "print(f\"Length of batch['images']: {len(batch['images'])}\")  # Should be batch_size (4)\n",
    "\n",
    "# Inspect the first tensor in the list\n",
    "first_tensor = batch['images'][0]\n",
    "print(f\"Type of first element: {type(first_tensor)}\")  # Should be a tensor\n",
    "print(f\"Shape of first element: {first_tensor.shape}\")  # Should be (5, C, H, W) if 5 images per pattern\n",
    "\n",
    "# Verify that all tensors in the list have the same structure\n",
    "for i, img_tensor in enumerate(batch[\"images\"]):\n",
    "    print(f\"Pattern {i}: Shape = {img_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch['images']), type(batch['images'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(batch):\n",
    "    pattern_ids = batch[\"pattern_id\"]  # Pattern labels\n",
    "    images_list = batch[\"images\"]  # List of tensors (each containing multiple images)\n",
    "\n",
    "    batch_size = len(images_list)  # Number of patterns\n",
    "    num_columns = 6  # First column for pattern ID, next 5 for images\n",
    "\n",
    "    fig, axes = plt.subplots(batch_size, num_columns, figsize=(batch_size * 2, num_columns * 2))\n",
    "\n",
    "    for row in range(batch_size):\n",
    "        # First column: Pattern ID\n",
    "        axes[row, 0].text(0.5, 0.5, pattern_ids[row], fontsize=12, ha='center', va='center')\n",
    "        axes[row, 0].set_xticks([])  # Remove ticks\n",
    "        axes[row, 0].set_yticks([])\n",
    "        axes[row, 0].spines['top'].set_visible(False)\n",
    "        axes[row, 0].spines['right'].set_visible(False)\n",
    "        axes[row, 0].spines['left'].set_visible(False)\n",
    "        axes[row, 0].spines['bottom'].set_visible(False)\n",
    "\n",
    "        # Plot images in remaining columns\n",
    "        num_images = images_list[row].shape[0]  # Number of images for this pattern\n",
    "        for col in range(1, num_columns):  # Columns 1 to 5 for images\n",
    "            ax = axes[row, col]\n",
    "            if col - 1 < num_images:  # Check if image exists\n",
    "                img = images_list[row][col - 1]  # Extract image tensor (C, H, W)\n",
    "                img = img.permute(1, 2, 0).numpy()  # Convert (C, H, W) → (H, W, C)\n",
    "                ax.imshow(img)\n",
    "            ax.axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "visualize_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: root\n",
      "  Subdirectory: subdir1\n",
      "  Subdirectory: subdir2\n",
      "  File: file1.txt\n",
      "Directory: root/subdir1\n",
      "  File: file3.txt\n",
      "  File: file2.txt\n",
      "Directory: root/subdir2\n",
      "  Subdirectory: subsubdir3\n",
      "  File: file4.txt\n",
      "Directory: root/subdir2/subsubdir3\n",
      "  File: file5.txt\n"
     ]
    }
   ],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(\"root\"):\n",
    "    print(f\"Directory: {dirpath}\")\n",
    "    for dirname in dirnames:  # Loop through subdirectories\n",
    "        print(f\"  Subdirectory: {dirname}\")\n",
    "    for filename in filenames:  # Loop through files\n",
    "        print(f\"  File: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
